{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "In this project you will predict fraudulent credit card transactions with the help of Machine learning models. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Basic Steps\n",
    "1. Importing necessary libraries\n",
    "2. Loading data\n",
    "3. Observe basic structure of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load data and observe basic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#observe the different feature type present in the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will observe the distribution of our classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=df['Class'].value_counts()\n",
    "normal_share=classes[0]/df['Class'].count()*100\n",
    "fraud_share=classes[1]/df['Class'].count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Percentage')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].bar(x=[\"normal_share\", \"fraud_share\"], height=classes)\n",
    "axs[0].set_title(\"Counts\")\n",
    "axs[1].bar(x=[\"normal_share\", \"fraud_share\"], height=[normal_share, fraud_share])\n",
    "axs[1].set_title(\"Percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f77c06ff1f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with time\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(df.Time, df.Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f77c07bca30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with Amount\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(df.Amount, df.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df=df.drop(\"Time\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Class #class variable\n",
    "X=df.drop(\"Class\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "369\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))\n",
    "print(np.sum(y_train))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "fig,axs=plt.subplots(6,5)\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            axs[i,j].hist(X_train[X_train.columns[5*i+j]], bins=100)\n",
    "            axs[i,j].set_title(X_train.columns[5*i+j])\n",
    "        except:\n",
    "            pass\n",
    "fig.set_size_inches(22,24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can see that there are many variables which have very high skewness so lets find the list of variable which have more than 0.5 skew and less than -0.5 skew`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See the features with more than 0.5 or less that -0.5 skew\n",
    "skew=X_train.skew()\n",
    "# Take absolute value of skew and then get all the columns whose absolute value of skew is more than 0.5\n",
    "skewed=skew[np.abs(skew)>0.5]\n",
    "print(skewed)\n",
    "print(\"The total number of features with skewness more than 0.5 or less than -0.5 are \", len(skewed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there is skewness present in the distribution use:\n",
    "- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11660077, -0.24624807, -1.21126569, ..., -0.09942353,\n",
       "        -0.02426017,  1.11998389],\n",
       "       [-0.8007408 ,  0.44011381,  0.62206941, ..., -0.11903135,\n",
       "        -0.02932256, -1.4485192 ],\n",
       "       [ 1.42613473,  0.11607881, -1.26746513, ..., -0.10881017,\n",
       "        -0.23037544, -0.39489373],\n",
       "       ...,\n",
       "       [ 1.34967801, -0.27895312, -1.02259027, ..., -0.28713909,\n",
       "        -0.22180959,  0.59394613],\n",
       "       [-0.60181077,  0.80366937, -0.16233207, ..., -0.58853555,\n",
       "         0.48508476, -0.72555558],\n",
       "       [ 0.46727185, -0.4919582 ,  0.00805671, ..., -0.09422002,\n",
       "         0.10855538,  1.15551083]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n",
    "power_trans=preprocessing.PowerTransformer(copy=False)\n",
    "power_trans.fit_transform(X_train)\n",
    "power_trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the histogram of a variable from the dataset again to see the result \n",
    "fig,axs=plt.subplots(6,5)\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            axs[i,j].hist(X_train[X_train.columns[5*i+j]], bins=100)\n",
    "            axs[i,j].set_title(X_train.columns[5*i+j])\n",
    "        except:\n",
    "            pass\n",
    "fig.set_size_inches(22,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now again See the features with more than 0.5 or less that -0.5 skew after power transform\n",
    "skew=X_train.skew()\n",
    "# Take absolute value of skew and then get all the columns whose absolute value of skew is more than 0.5\n",
    "skewed=skew[np.abs(skew)>0.5]\n",
    "print(skewed)\n",
    "print(\"The total number of features with skewness more than 0.5 or less than -0.5 are \", len(skewed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Building\n",
    "- Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model #import the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Cross validation done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross validation manually\n",
    "skf=model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "accuracy_scores =[]\n",
    "recall_scores = []\n",
    "precission_scores = []\n",
    "AUC_ROC=[]\n",
    "logistic_model=linear_model.LogisticRegression( random_state=100)\n",
    "for train_index, test_index in skf.split(X_train,y_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    logistic_model.fit(X_train_cv, y_train_cv)\n",
    "    predictions = logistic_model.predict(X_test_cv)\n",
    "    pred_proba= logistic_model.predict_proba(X_test_cv)[:,1]\n",
    "    accuracy_scores.append(metrics.accuracy_score(y_test_cv, predictions))\n",
    "    recall_scores.append(metrics.recall_score(y_test_cv, predictions))\n",
    "    precission_scores.append(metrics.precision_score(y_test_cv, predictions))\n",
    "    AUC_ROC.append(metrics.roc_auc_score(y_test_cv,pred_proba))\n",
    "print(\"The average accurcay score is\", np.mean(accuracy_scores))\n",
    "print(\"The average recall score is\", np.mean(recall_scores))\n",
    "print(\"The average precision score is\", np.mean(precission_scores))\n",
    "print(\"The average ROC AUC score is\", np.mean(AUC_ROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Hyperparameter Tunning for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "params = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "skf=model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "logistic_model=linear_model.LogisticRegression(random_state=100, max_iter=1000)\n",
    "\n",
    "# The best evaluation metric to evealuate the strength of a model is auc roc score\n",
    "grid_search = model_selection.GridSearchCV(estimator=logistic_model, param_grid=params, n_jobs=-1, cv=skf, scoring='roc_auc', error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "end=time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best score\n",
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Logistic regression model using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using these optimum hyperparametrs\n",
    "logistic_model=linear_model.LogisticRegression(penalty='l2', C=0.01, random_state=100, solver='liblinear',max_iter=1000)\n",
    "logistic_model.fit(X_train,y_train)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba= logistic_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=logistic_model.predict_proba(X_train)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Logistic regression Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'minkowski',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': None,\n",
      " 'n_neighbors': 5,\n",
      " 'p': 2,\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# See the list of parameters\n",
    "pprint(knn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
      " 'n_neighbors': array([ 3,  5,  7,  9, 11]),\n",
      " 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# Set N neighbours\n",
    "n_neighbors = np.arange(3,13,2)\n",
    "# Set weights\n",
    "weights = ['uniform', 'distance']\n",
    "# Set distance metrics\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid param\n",
    "param_grid = {\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Hyperparameter Tunning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# Initiate the Stratified K fold\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=knn, param_grid=param_grid, n_jobs=-1, cv=skf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 KNN using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = uniform, metric=manhattan)\n",
    "knn.fit(X_train, y_train)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=knn.predict_proba(X_train)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 KNN Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': None,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': None,\n",
      " 'colsample_bynode': None,\n",
      " 'colsample_bytree': None,\n",
      " 'gamma': None,\n",
      " 'gpu_id': None,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': None,\n",
      " 'max_delta_step': None,\n",
      " 'max_depth': None,\n",
      " 'min_child_weight': None,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'num_parallel_tree': None,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': None,\n",
      " 'reg_alpha': None,\n",
      " 'reg_lambda': None,\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': None,\n",
      " 'tree_method': None,\n",
      " 'use_label_encoder': True,\n",
      " 'validate_parameters': None,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "pprint(xgb.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Hyperparameter Tunning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ]\n",
    "max_depth = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "gamma = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "param_grid={\"learning_rate\":learning_rate, \"max_depth\":max_depth, \"gamma\"=gamma}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate XGBoost Classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Initiate the Stratified K fold\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=xgb, param_grid=param_grid, n_jobs=-1, cv=skf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 XGBoost using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate = 0.20, max_depth = 5, gamma = 0.3)\n",
    "xgb.fit(X_train, y_train)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=xgb.predict_proba(X_train)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 XGBoost Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choose the best model without Oversampling\n",
    "## 4.1 Proceed with the model which shows the best result \n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ___  #initialise the model with optimum hyperparameters\n",
    "clf.fit(X_train, y_train)\n",
    "print --> #print the evaluation score on the X_test by choosing the best evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Print the important features of the best model to understand the dataset\n",
    "- This will not give much explanation on the already transformed dataset\n",
    "- But it will help us in understanding if the dataset is not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building with balancing Classes\n",
    "\n",
    "##### Perform class balancing with :\n",
    "- Random Oversampling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn import over_sampling #- import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance classes on X_train_cv & y_train_cv using Random Oversampling\n",
    "ro = over_sampling.RandomOverSampler(random_state=100)\n",
    "X_train_ro, y_train_ro = ro.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the class distribution of oversampled data\n",
    "classes=y_train_ro.value_counts()\n",
    "normal_share=classes[0]/len(y_train_ro)*100\n",
    "fraud_share=classes[1]/len(y_train_ro)*100\n",
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].bar(x=[\"normal_share\", \"fraud_share\"], height=classes)\n",
    "axs[0].set_title(\"Counts\")\n",
    "axs[1].bar(x=[\"normal_share\", \"fraud_share\"], height=[normal_share, fraud_share])\n",
    "axs[1].set_title(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our data is oversampled properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Logistic Regression with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Initiate Logistic regression object\n",
    "logistic_model=linear_model.LogisticRegression()\n",
    "# See the list of parameters\n",
    "pprint(logistic_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Hyperparameter Tunning for Logistic regression with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "# Penalty Regularization\n",
    "penalty = ['l2']\n",
    "c_values = [ 100, 10, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "params = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "# Initiate K fold\n",
    "kf=model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Logistic regression model\n",
    "logistic_model=linear_model.LogisticRegression(random_state=100, max_iter=1000)\n",
    "# The best evaluation metric to evealuate the strength of a model is auc roc score\n",
    "grid_search = model_selection.GridSearchCV(estimator=logistic_model, param_grid=params, n_jobs=-1, cv=kf, scoring='roc_auc', error_score=0)\n",
    "grid_result = grid_search.fit(X_train_ro, y_train_ro)\n",
    "end=time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best score\n",
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Logistic Regression with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using these optimum hyperparametrs\n",
    "logistic_model=linear_model.LogisticRegression(penalty='l2', C=100, random_state=100, solver='newton-cg',max_iter=1000)\n",
    "logistic_model.fit(X_train_ro,y_train_ro)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba= logistic_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.999 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=logistic_model.predict_proba(X_train_ro)[:,1]>0.999\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Logistic Regression with Random OverSampler model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_ro, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_ro, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 KNN with Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'minkowski',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': None,\n",
      " 'n_neighbors': 5,\n",
      " 'p': 2,\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# See the list of parameters\n",
    "pprint(knn.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Hyperparameter Tunning for KNN with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
      " 'n_neighbors': array([ 3,  5,  7,  9, 11]),\n",
      " 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# Set N neighbours\n",
    "n_neighbors = np.arange(3,13,2)\n",
    "# Set weights\n",
    "weights = ['uniform', 'distance']\n",
    "# Set distance metrics\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid param\n",
    "param_grid = {\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# Initiate the K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=knn, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_ro, y_train_ro)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 KNN using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric)\n",
    "knn.fit(X_train_ro, y_train_ro)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=knn.predict_proba(X_train_ro)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 KNN with Random OverSampler Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_ro, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_ro, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 XGBoost with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': None,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': None,\n",
      " 'colsample_bynode': None,\n",
      " 'colsample_bytree': None,\n",
      " 'gamma': None,\n",
      " 'gpu_id': None,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': None,\n",
      " 'max_delta_step': None,\n",
      " 'max_depth': None,\n",
      " 'min_child_weight': None,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'num_parallel_tree': None,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': None,\n",
      " 'reg_alpha': None,\n",
      " 'reg_lambda': None,\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': None,\n",
      " 'tree_method': None,\n",
      " 'use_label_encoder': True,\n",
      " 'validate_parameters': None,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "pprint(xgb.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Hyperparameter Tunning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ]\n",
    "max_depth = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "gamma = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "param_grid={\"learning_rate\":learning_rate, \"max_depth\":max_depth, \"gamma\"=gamma}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate XGBoost Classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Initiate the Stratified K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=xgb, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_ro, y_train_ro)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 XGBoost using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate = 0.20, max_depth = 5, gamma = 0.3)\n",
    "xgb.fit(X_train_ro, y_train_ro)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=xgb.predict_proba(X_train_ro)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 XGBoost with Random Oversampling Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_ro, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_ro, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SMOTE\n",
    "##### Build models on other algorithms to see the better performing on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sm = over_sampling.SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from SMOTE are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from SMOTE, we do\n",
    "X_train_smote_1 = X_train_smote[X_train.shape[0]:].to_numpy()\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[20,20])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial SMOTE Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the class distribution of oversampled data\n",
    "classes=y_train_smote.value_counts()\n",
    "normal_share=classes[0]/len(y_train_smote)*100\n",
    "fraud_share=classes[1]/len(y_train_smote)*100\n",
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].bar(x=[\"normal_share\", \"fraud_share\"], height=classes)\n",
    "axs[0].set_title(\"Counts\")\n",
    "axs[1].bar(x=[\"normal_share\", \"fraud_share\"], height=[normal_share, fraud_share])\n",
    "axs[1].set_title(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Logistic regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Initiate Logistic regression object\n",
    "logistic_model=linear_model.LogisticRegression()\n",
    "# See the list of parameters\n",
    "pprint(logistic_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Hyperparameter Tunning for Logistic regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "# Penalty Regularization\n",
    "penalty = ['l2']\n",
    "c_values = [ 100, 10, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "params = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "kf=model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "logistic_model=linear_model.LogisticRegression(random_state=100, max_iter=1000)\n",
    "# define grid search\n",
    "params = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "# The best evaluation metric to evealuate the strength of a model is auc roc score\n",
    "grid_search = model_selection.GridSearchCV(estimator=logistic_model, param_grid=params, n_jobs=-1, cv=kf, scoring='roc_auc', error_score=0)\n",
    "grid_result = grid_search.fit(X_train_smote, y_train_smote)\n",
    "end=time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best score\n",
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Logistic Regression model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using these optimum hyperparametrs\n",
    "logistic_model=linear_model.LogisticRegression(penalty='l2', C=100, random_state=100, solver='newton-cg',max_iter=1000)\n",
    "logistic_model.fit(X_train_smote,y_train_smote)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba= logistic_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.999 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=logistic_model.predict_proba(X_train_smote)[:,1]>0.999\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Logistic regression with SMOTE model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_smote, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_smote, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 KNN with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'minkowski',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': None,\n",
      " 'n_neighbors': 5,\n",
      " 'p': 2,\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# See the list of parameters\n",
    "pprint(knn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
      " 'n_neighbors': array([ 3,  5,  7,  9, 11]),\n",
      " 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# Set N neighbours\n",
    "n_neighbors = np.arange(3,13,2)\n",
    "# Set weights\n",
    "weights = ['uniform', 'distance']\n",
    "# Set distance metrics\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid param\n",
    "param_grid = {\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Hyperparameter Tunning for KNN with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# Initiate the K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=knn, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 KNN using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric)\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=knn.predict_proba(X_train_smote)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 KNN with SMOTE Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_smote, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_smote, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': None,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': None,\n",
      " 'colsample_bynode': None,\n",
      " 'colsample_bytree': None,\n",
      " 'gamma': None,\n",
      " 'gpu_id': None,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': None,\n",
      " 'max_delta_step': None,\n",
      " 'max_depth': None,\n",
      " 'min_child_weight': None,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'num_parallel_tree': None,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': None,\n",
      " 'reg_alpha': None,\n",
      " 'reg_lambda': None,\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': None,\n",
      " 'tree_method': None,\n",
      " 'use_label_encoder': True,\n",
      " 'validate_parameters': None,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "pprint(xgb.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Hyperparameter Tunning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ]\n",
    "max_depth = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "gamma = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "param_grid={\"learning_rate\":learning_rate, \"max_depth\":max_depth, \"gamma\"=gamma}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate XGBoost Classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Initiate the Stratified K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=xgb, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 XGBoost using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate = 0.20, max_depth = 5, gamma = 0.3)\n",
    "xgb.fit(X_train_smote, y_train_smote)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=xgb.predict_proba(X_train_smote)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 XGBoost with SMOTE Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_smote, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_smote, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ADASYN\n",
    "##### Build models on other algorithms to see the better performing on ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn import over_sampling\n",
    "\n",
    "ada = over_sampling.ADASYN(random_state=0)\n",
    "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from ADASYN are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from ADASYN, we do\n",
    "X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:].to_numpy()\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[20,20])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_adasyn_1[:X_train_1.shape[0], 0], X_train_adasyn_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial ADASYN Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see the class distribution of oversampled data\n",
    "classes=y_train_adasyn.value_counts()\n",
    "normal_share=classes[0]/len(y_train_adasyn)*100\n",
    "fraud_share=classes[1]/len(y_train_adasyn)*100\n",
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].bar(x=[\"normal_share\", \"fraud_share\"], height=classes)\n",
    "axs[0].set_title(\"Counts\")\n",
    "axs[1].bar(x=[\"normal_share\", \"fraud_share\"], height=[normal_share, fraud_share])\n",
    "axs[1].set_title(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Logistic regression with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Initiate Logistic regression object\n",
    "logistic_model=linear_model.LogisticRegression()\n",
    "# See the list of parameters\n",
    "pprint(logistic_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Hyperparameter Tunning for Logistic regression with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "params = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "#perform hyperparameter tuning\n",
    "kf=model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "logistic_model=linear_model.LogisticRegression(random_state=100, max_iter=1000)\n",
    "# The best evaluation metric to evealuate the strength of a model is auc roc score\n",
    "grid_search = model_selection.GridSearchCV(estimator=logistic_model, param_grid=params, n_jobs=-1, cv=kf, scoring='roc_auc', error_score=0)\n",
    "grid_result = grid_search.fit(X_train_adasyn, y_train_adasyn)\n",
    "end=time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best score\n",
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Logistic regression using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using these optimum hyperparametrs\n",
    "logistic_model=linear_model.LogisticRegression(penalty='l2', C=100, random_state=100, solver='newton-cg',max_iter=1000)\n",
    "logistic_model.fit(X_train_adasyn,y_train_adasyn)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba= logistic_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=logistic_model.predict_proba(X_train_adasyn)[:,1]>0.999\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Logistic regression  with ADASYN Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 KNN with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'minkowski',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': None,\n",
      " 'n_neighbors': 5,\n",
      " 'p': 2,\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# See the list of parameters\n",
    "pprint(knn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
      " 'n_neighbors': array([ 3,  5,  7,  9, 11]),\n",
      " 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# Set N neighbours\n",
    "n_neighbors = np.arange(3,13,2)\n",
    "# Set weights\n",
    "weights = ['uniform', 'distance']\n",
    "# Set distance metrics\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# grid param\n",
    "param_grid = {\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Hyperparameter Tunning for KNN with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate KNN Classifier object\n",
    "knn = KNeighborsClassifier()\n",
    "# Initiate the K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=knn, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_adasyn, y_train_adasyn)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 KNN using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(\"n_neighbors\" : n_neighbors, \"weights\" : weights, \"metric\" : metric)\n",
    "knn.fit(X_train_adasyn, y_train_adasyn)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=knn.predict_proba(X_train_adasyn)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 KNN with ADASYN Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 XGBoost with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': None,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': None,\n",
      " 'colsample_bynode': None,\n",
      " 'colsample_bytree': None,\n",
      " 'gamma': None,\n",
      " 'gpu_id': None,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': None,\n",
      " 'max_delta_step': None,\n",
      " 'max_depth': None,\n",
      " 'min_child_weight': None,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'num_parallel_tree': None,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': None,\n",
      " 'reg_alpha': None,\n",
      " 'reg_lambda': None,\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': None,\n",
      " 'tree_method': None,\n",
      " 'use_label_encoder': True,\n",
      " 'validate_parameters': None,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "pprint(xgb.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Hyperparameter Tunning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ]\n",
    "max_depth = [ 3, 4, 5, 6, 8, 10, 12, 15]\n",
    "gamma = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "param_grid={\"learning_rate\":learning_rate, \"max_depth\":max_depth, \"gamma\"=gamma}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# Initiate XGBoost Classifier object\n",
    "xgb = XGBClassifier()\n",
    "# Initiate the Stratified K fold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# Initiate Grid search\n",
    "grid_search = model_selection.GridSearchCV(estimator=xgb, param_grid=param_grid, n_jobs=-1, cv=kf, scoring='roc_auc',error_score=0)\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train_adasyn, y_train_adasyn)\n",
    "end= time.time()\n",
    "print(\"Time taken to run this is: \", round((end-start)/60, 2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best estimator\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the best params from random grid search\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 XGBoost using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate = 0.20, max_depth = 5, gamma = 0.3)\n",
    "xgb.fit(X_train_adasyn, y_train_adasyn)\n",
    "# Find the probability of the target to be 1\n",
    "predict_proba = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict_proba)\n",
    "# Plot the ROC curve to see which value of tpr and FPR will be a good option to choose\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that 0.85 will be a good value for TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph between tpr and thresholds to choose the threshold\n",
    "plt.plot(thresholds, tpr)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"TPR vs Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the value of threshold correspond to TPR =0.85 should be around 0.06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the threshold to be 0.06 the classes of the target will be\n",
    "# Prediction for train data\n",
    "y_train_pred=xgb.predict_proba(X_train_adasyn)[:,1]>0.07\n",
    "# Prediction for test data\n",
    "y_pred=predict_proba>0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 XGBoost with ADASYN Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall score for the train data is: \", metrics.recall_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The precision score for the train data is: \", metrics.precision_score(y_train_adasyn, y_train_pred))\n",
    "print(\"The recall score for the test data is: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"The precision score for the test data is: \", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Final Selection of Model and Over Sampling Method\n",
    "### Select the oversampling method which shows the best result on a model\n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the best oversampling method on X_train & y_train\n",
    "\n",
    "clf = ___  #initialise the model with optimum hyperparameters\n",
    "clf.fit( ) # fit on the balanced dataset\n",
    "print() --> #print the evaluation score on the X_test by choosing the best evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the important features of the best model to understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-13 and Index-9 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Print the FPR,TPR & select the best threshold from the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train auc =', metrics.roc_auc_score(_________)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(_________)\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 473.597969,
   "end_time": "2021-01-03T05:26:57.795169",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-03T05:19:04.197200",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
